{"cells":[{"cell_type":"markdown","metadata":{"id":"BRCG4DT_SYit"},"source":["# Problem 4.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wszztea3SYix"},"outputs":[],"source":["'''\n","Things to note:\n","\n","- Now we are using the skorch library which allows us to do parameter tunning in the same way as for\n","other classifiers in sklearn. \n","- The code to add L1 regularization is already implemented.\n","\n","'''"]},{"cell_type":"code","source":["# need to install skorch if you haven't done that\n","!pip install skorch"],"metadata":{"id":"ckSS2liekFUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eF-i41NUSYiz"},"outputs":[],"source":["'''\n","Import packages \n","'''\n","\n","%matplotlib inline\n","\n","from sklearn.datasets import fetch_openml # Import MNIST from a Package\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Standard PyTorch Imports\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","# We will be using the PyTorch Wrapper Framework skorch to help simplify the coding\n","from skorch import NeuralNetClassifier\n","\n","# We need to import some Sci-kit Learn modules for computation purposes.\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","\n","# Global Settings - These settings are critical\n","\n","# If CUDA is available, use CUDA or else default to CPU.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Setting a seed for torch\n","torch.manual_seed(0)\n"]},{"cell_type":"code","source":["'''\n","Import the data\n","'''\n","# select the root = ....\n","\n","mnist = torchvision.datasets.MNIST(root = '/data', \n","                                   train = True, \n","                                   transform = transforms.ToTensor(),  \n","                                   download = True)\n","\n","test_dataset = torchvision.datasets.MNIST(root = '/data', \n","                                          train = False, \n","                                          transform = transforms.ToTensor())\n","\n","\n","X_train = mnist.data\n","y_train = mnist.targets\n","\n","X_test = test_dataset.data\n","y_test = test_dataset.targets\n","\n","\n","'''\n","Step -- Normalize each input from [0.0,1.0] range\n","'''\n","\n","\n","'''\n","Step -- Reshape X to have 4 dimension that is batch_size, channels, Height, Width\n","'''\n"],"metadata":{"id":"9NQ-9dPZjlg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","'''\n","Will do some basic plotting to get a feel for the data that we imported.\n","\n","'''\n","\n","def plot_example(X, y):\n","    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n","    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n","        plt.subplot(151 + i)\n","        plt.imshow(img)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(y.item())\n","        \n","plot_example(X_train, y_train)"],"metadata":{"id":"50DnSJHmj4El"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgQGKYQIlrFt"},"outputs":[],"source":["# build your CNN \n","class CNN(nn.Module):\n","    def __init__(self, dropout = 0.4):\n","        super(CNN, self).__init__()\n","        '''Step -- Fill in the architecture'''\n","\n","    def forward(self, x):\n","        '''Step -- Fill in the Forward propagation function'''\n","\n","        return output"]},{"cell_type":"code","source":["# Adding L1 regularization\n","\n","class RegularizedNet(NeuralNetClassifier):\n","    \n","    ''''''\n","    \n","    def __init__(self, *args, lambda1 = 0.01, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.lambda1 = lambda1\n","    \n","    ''' *** Explain -- What is the following method doing? Explain in detail in the main pdf ***'''\n","    \n","    def get_loss(self, y_pred, y_true, X = None, training = False):\n","        loss = super().get_loss(y_pred, y_true, X = X, training = training)\n","        loss += self.lambda1 * sum([w.abs().sum() for w in self.module_.parameters()])\n","        return loss"],"metadata":{"id":"tIu6kjIrN2pY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print out the structure of the model \n","cnn = CNN()\n","print(cnn)"],"metadata":{"id":"IyY0RG1s2KWZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Check Device == 'cuda'. USE GPU !!!!. Otherwise things will be super slow. Check\n","https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d \n","'''\n","\n","print('Using Device = ',device)"],"metadata":{"id":"6FzYSj9AzrD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSDyLC3CSYi1"},"outputs":[],"source":["'''\n","Here we define the RegularizedNet. Make sure you use nn.NLLLoss. Thus, you have to use a correct last activation\n","in the forward method of your network\n","\n","We can specify different parameters such as learning rate (lr), our optimizar (start with standard SGD, in 4.3 we will\n","try another ones), batch size etc.\n","To define the arquitecture parameters for CNN write them as module__<name of your parameter> = ....\n","\n","Since we have to train it first with L2 regularization lambda1 should be equal to 0\n","'''\n","cnn = RegularizedNet(module = CNN, \n","                     max_epochs = ...,\n","                     criterion = torch.nn.NLLLoss, \n","                     optimizer = ...,\n","                     lr = ..., \n","                     lambda1 = 0,\n","                     module__dropout = ...,\n","                     optimizer__weight_decay = ...,\n","                     device = device)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gb6yTL_ulzD6"},"outputs":[],"source":["'''Step - train the network'''\n","\n","cnn.fit(X_train, y_train)\n","y_pred_probs = cnn.predict(X_test)\n","\n","'''\n","Look how your loss is going down as well as the validation accuracy is increasing \n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFN1PQ50lzGi"},"outputs":[],"source":["'''Step - Predict for the test set and print the final accuracy score, your validation accuracy obtained in the previous\n","cell should be similar to the accuracy in the test set\n","'''\n","y_pred = cnn.predict(X_test)\n","accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXbcnqA7lzIi"},"outputs":[],"source":["'''The idea is that you should get more than 98% of accuracy, so try different parameters as requested in the main pdf\n","The fit method is already showing you a validation error which can be used to compare between different parameters.\n","\n","for the final submission leave the best parameters in your RegularizedNet(...)\n","'''\n","'''\n","Instead of doing it manually skorch allows us to use GridSearchCV from sklearn \n","'''\n","from sklearn.model_selection import GridSearchCV\n","\n","'''\n","Step - define a grid with some parameters that you consider may give you good results and \n","the code will do the rest for you\n","\n","* Especially take into account the parameters we are asking for to tune:  \n","Learning rate, regularization parameter, and the number of nodes\n","\n","'''\n","# you can use cnn.get_params().keys() to get all the parameters that you can tune\n","\n","grid = {\n","    'lr': [0.001, 0.1, ...],\n","    'other parameters': [...]\n","}\n","\n","'''\n","Important that you keep refit = True\n","'''\n","gs = GridSearchCV(cnn, grid, refit = True, cv = 5, scoring = 'accuracy')\n","\n","\n","'''\n","Finally fit\n","'''\n","gs.fit(X_train, y_train)\n","\n","#Report Best Parameters\n","print(gs.best_score_, gs.best_params_)\n"]},{"cell_type":"markdown","metadata":{"id":"CQHujgjwSYi3"},"source":["# Problem 4.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGwtTINmSYi4"},"outputs":[],"source":["'''\n","Step - Now we are going to train the network with L1 regularization instead of L2 and dropout,\n","we are going to create a new network with a lambda1 parameter different than 0\n","- Keep the rest of the parameters you used in the previous network but dropout and L2 parameters are 0 \n","'''\n","\n","cnn_l1 = RegularizedNet(module = CNN, criterion = torch.nn.NLLLoss, \n","                        optimizer= ..., lr = ..., lambda1 = ...,  module__dropout = 0,\n","                        optimizer__weight_decay = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Knz4An8-lvAt"},"outputs":[],"source":["#Refer to https://skorch.readthedocs.io/en/stable/user/save_load.html\n","\n","import pickle\n","\n","#Transfer Learning - \n","#The following code will transfer the weights from L2 trained networks to initialize the new network before L1 training\n","\n","'''\n","\n","Notes - I assumed you have trained your L2 network using Skorch's NeuralNetClassifier\n","        I assume your trained model object is called \"cnn\"\n","\n","'''\n","\n","#Step - 1 - Save weights from L2 network\n","\n","cnn.save_params(f_params='some-file.pkl') # This comes after cnn.fit(). You are saving the model weights in a pickle\n","\n","\n","#Step - 2\n","\n","cnn_l1.initialize()\n","cnn_l1.load_params(f_params='some-file.pkl')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2GJ0moHSYi5"},"outputs":[],"source":["'''\n","Step train the network with the weights transfered from cnn, and perform grid search for the lambda1 parameter\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMLkSv3YSYi5"},"outputs":[],"source":["'''\n","Step train the network with default initialization parameters\n","we can simply initialize with the same code as before (make sure to use the same parameters)\n","\n","perform grid search for the lambda1 parameter as in the previous cell\n","'''\n","\n","cnn_l1 = RegularizedNet(module = CNN, criterion=torch.nn.NLLLoss, \n","                        optimizer= ..., lr = 0.001, lambda1 = ...,  module__dropout = 0,\n","                        optimizer__weight_decay = 0)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a0PfyEv7SYi5"},"source":["# Problem 4.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PScGPwtFSYi6"},"outputs":[],"source":["'''\n","Keeping all the parameters for which you have got the best results before\n","try different optimizers.\n","\n","Basically create the same cnn_l1 or new_net but train it with the requested optimizers in the pdf\n","\n","GridSeacrh is not required but you can do it if you want for the different parameters of the optimizers\n","\n","Notice you already train it with SGD in the previous problems\n","'''\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dp1ShZzSYi6"},"outputs":[],"source":["# Adam (look how I defined optimizer)\n","\n","cnn_l1 = RegularizedNet(module = CNN, criterion=torch.nn.NLLLoss, \n","                        optimizer = torch.optim.Adam, lr = 0.001, lambda1 = ...,  module__dropout = 0,\n","                        optimizer__weight_decay = 0)\n","\n","'''\n","-Step now fit it and print the accuracy as in problem 1\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_EHlK-hSYi6"},"outputs":[],"source":["# SGD with momentum "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"doVkvaE6SYi6"},"outputs":[],"source":["# AdaGrad"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"private_outputs":true,"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}