{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:29:15.942335700Z",
     "start_time": "2023-10-12T23:29:15.917928800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 784)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = loadmat('mnist_49_3000.mat')\n",
    "X = mnist['x']\n",
    "y = mnist['y'][0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.T, y, test_size=1000, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:29:16.042571800Z",
     "start_time": "2023-10-12T23:29:15.930829300Z"
    }
   },
   "id": "49b689cd75f07ed5"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def converter(inp):\n",
    "    if inp > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "y_train_mod = [converter(val) for val in y_train]\n",
    "y_test_mod  = [converter(val) for val in y_test]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:29:16.050066400Z",
     "start_time": "2023-10-12T23:29:16.042571800Z"
    }
   },
   "id": "e215e3f0e7c62f38"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, x_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(x_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "    def predict(self, x, threshold):\n",
    "        return self.forward(x) >= threshold\n",
    "\n",
    "class LogisticRegressionGradientDescent:\n",
    "    def __init__(self, lr=0.01, lamb=10, num_iter=1000, x_dim=785, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.lamb = lamb\n",
    "        self.num_iter = num_iter\n",
    "        self.x_dim = x_dim\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.model = LogisticRegression(x_dim)\n",
    "        \n",
    "    def __add_intercept(self, x):\n",
    "        intercept = np.ones((x.shape[0], 1))\n",
    "        return np.concatenate((intercept, x), axis=1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        if self.fit_intercept:\n",
    "            x = self.__add_intercept(x)\n",
    "        \n",
    "        x = torch.tensor(x).float()\n",
    "        y = torch.tensor(y).float()\n",
    "        \n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        print(\"Training Error:\")\n",
    "        for epoch in range(self.num_iter):\n",
    "            # Predict and get weights\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.model.forward(x)\n",
    "            theta = self.model.linear.weight\n",
    "            \n",
    "            # Calculate loss using the function from the 4.1 in homework document\n",
    "            regularization_offset = self.lamb * (torch.dot(theta[:, 0], theta[:, 0]))\n",
    "            loss = criterion(y_pred, y[:, None]) + regularization_offset\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}/{num_iter}: {float(loss)}\")\n",
    "        \n",
    "        print(f\"Train Error: {float(loss)}\")\n",
    "    \n",
    "    def predict(self, x, threshold):\n",
    "        if self.fit_intercept:\n",
    "            x = self.__add_intercept(x)\n",
    "        x = torch.tensor(x).float()\n",
    "        preds = self.model.forward(x)\n",
    "        return preds >= threshold\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:46:03.055223200Z",
     "start_time": "2023-10-12T23:46:03.023221100Z"
    }
   },
   "id": "e2d17cf8b69f4d1a"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.1\n",
      "lambda: 0.01\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6980333924293518\n",
      "Epoch 100/1000: 0.1914200484752655\n",
      "Epoch 200/1000: 0.1479988545179367\n",
      "Epoch 300/1000: 0.12901455163955688\n",
      "Epoch 400/1000: 0.1176883652806282\n",
      "Epoch 500/1000: 0.10990528762340546\n",
      "Epoch 600/1000: 0.10409972816705704\n",
      "Epoch 700/1000: 0.09952925145626068\n",
      "Epoch 800/1000: 0.09579091519117355\n",
      "Epoch 900/1000: 0.09264496713876724\n",
      "Train Error: 0.08996408432722092\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 959/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 953/1000\n",
      "\n",
      "lambda: 0.1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6915158033370972\n",
      "Epoch 100/1000: 0.1915685534477234\n",
      "Epoch 200/1000: 0.14848464727401733\n",
      "Epoch 300/1000: 0.1295381635427475\n",
      "Epoch 400/1000: 0.11820440739393234\n",
      "Epoch 500/1000: 0.11040231585502625\n",
      "Epoch 600/1000: 0.10457470268011093\n",
      "Epoch 700/1000: 0.09998181462287903\n",
      "Epoch 800/1000: 0.0962216854095459\n",
      "Epoch 900/1000: 0.09305496513843536\n",
      "Train Error: 0.09035465121269226\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 958/1000\n",
      "0.4: Correctly predicted: 974/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 952/1000\n",
      "\n",
      "lambda: 0.5\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.7149507403373718\n",
      "Epoch 100/1000: 0.192307248711586\n",
      "Epoch 200/1000: 0.14873433113098145\n",
      "Epoch 300/1000: 0.1296384185552597\n",
      "Epoch 400/1000: 0.11823298782110214\n",
      "Epoch 500/1000: 0.11039052158594131\n",
      "Epoch 600/1000: 0.10453835874795914\n",
      "Epoch 700/1000: 0.09992998838424683\n",
      "Epoch 800/1000: 0.09615994989871979\n",
      "Epoch 900/1000: 0.09298692643642426\n",
      "Train Error: 0.09028276056051254\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 956/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 969/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 952/1000\n",
      "\n",
      "lambda: 0.9\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6868414282798767\n",
      "Epoch 100/1000: 0.190045565366745\n",
      "Epoch 200/1000: 0.14713196456432343\n",
      "Epoch 300/1000: 0.128371924161911\n",
      "Epoch 400/1000: 0.11717810481786728\n",
      "Epoch 500/1000: 0.10948256403207779\n",
      "Epoch 600/1000: 0.10373899340629578\n",
      "Epoch 700/1000: 0.09921453893184662\n",
      "Epoch 800/1000: 0.09551170468330383\n",
      "Epoch 900/1000: 0.09239395707845688\n",
      "Train Error: 0.08973586559295654\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 959/1000\n",
      "0.4: Correctly predicted: 973/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 955/1000\n",
      "\n",
      "lambda: 1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.7210092544555664\n",
      "Epoch 100/1000: 0.19244737923145294\n",
      "Epoch 200/1000: 0.14866141974925995\n",
      "Epoch 300/1000: 0.1295236200094223\n",
      "Epoch 400/1000: 0.11811123043298721\n",
      "Epoch 500/1000: 0.11027239263057709\n",
      "Epoch 600/1000: 0.10442734509706497\n",
      "Epoch 700/1000: 0.09982699155807495\n",
      "Epoch 800/1000: 0.09606487303972244\n",
      "Epoch 900/1000: 0.09289931505918503\n",
      "Train Error: 0.09020193666219711\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 961/1000\n",
      "0.4: Correctly predicted: 974/1000\n",
      "0.5: Correctly predicted: 970/1000\n",
      "0.6: Correctly predicted: 972/1000\n",
      "0.75: Correctly predicted: 954/1000\n",
      "\n",
      "\n",
      "Learning Rate: 0.5\n",
      "lambda: 0.01\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6786928176879883\n",
      "Epoch 100/1000: 0.1065029427409172\n",
      "Epoch 200/1000: 0.08909832686185837\n",
      "Epoch 300/1000: 0.08001633733510971\n",
      "Epoch 400/1000: 0.07395295053720474\n",
      "Epoch 500/1000: 0.06942848116159439\n",
      "Epoch 600/1000: 0.06583243608474731\n",
      "Epoch 700/1000: 0.06285489350557327\n",
      "Epoch 800/1000: 0.0603172741830349\n",
      "Epoch 900/1000: 0.058107614517211914\n",
      "Train Error: 0.056169863790273666\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 964/1000\n",
      "0.4: Correctly predicted: 973/1000\n",
      "0.5: Correctly predicted: 972/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 967/1000\n",
      "\n",
      "lambda: 0.1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.696719765663147\n",
      "Epoch 100/1000: 0.10586850345134735\n",
      "Epoch 200/1000: 0.08869589865207672\n",
      "Epoch 300/1000: 0.07970181852579117\n",
      "Epoch 400/1000: 0.07368697226047516\n",
      "Epoch 500/1000: 0.06919422000646591\n",
      "Epoch 600/1000: 0.06562094390392303\n",
      "Epoch 700/1000: 0.06266079843044281\n",
      "Epoch 800/1000: 0.060137081891298294\n",
      "Epoch 900/1000: 0.057938914746046066\n",
      "Train Error: 0.05601080507040024\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 963/1000\n",
      "0.4: Correctly predicted: 973/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 966/1000\n",
      "\n",
      "lambda: 0.5\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6787808537483215\n",
      "Epoch 100/1000: 0.10583992302417755\n",
      "Epoch 200/1000: 0.08867109566926956\n",
      "Epoch 300/1000: 0.07966560870409012\n",
      "Epoch 400/1000: 0.07364515215158463\n",
      "Epoch 500/1000: 0.0691506415605545\n",
      "Epoch 600/1000: 0.06557765603065491\n",
      "Epoch 700/1000: 0.06261885911226273\n",
      "Epoch 800/1000: 0.060096994042396545\n",
      "Epoch 900/1000: 0.05790090933442116\n",
      "Train Error: 0.05597493797540665\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 963/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 972/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 965/1000\n",
      "\n",
      "lambda: 0.9\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.684288740158081\n",
      "Epoch 100/1000: 0.10589006543159485\n",
      "Epoch 200/1000: 0.08875907212495804\n",
      "Epoch 300/1000: 0.07977040857076645\n",
      "Epoch 400/1000: 0.07375676929950714\n",
      "Epoch 500/1000: 0.06926397234201431\n",
      "Epoch 600/1000: 0.06568983197212219\n",
      "Epoch 700/1000: 0.06272818148136139\n",
      "Epoch 800/1000: 0.060202453285455704\n",
      "Epoch 900/1000: 0.05800197646021843\n",
      "Train Error: 0.05607141926884651\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 963/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 973/1000\n",
      "0.75: Correctly predicted: 967/1000\n",
      "\n",
      "lambda: 1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.702730119228363\n",
      "Epoch 100/1000: 0.10575983673334122\n",
      "Epoch 200/1000: 0.08865837007761002\n",
      "Epoch 300/1000: 0.07968694716691971\n",
      "Epoch 400/1000: 0.07368365675210953\n",
      "Epoch 500/1000: 0.06919785588979721\n",
      "Epoch 600/1000: 0.06562906503677368\n",
      "Epoch 700/1000: 0.06267190724611282\n",
      "Epoch 800/1000: 0.06015019863843918\n",
      "Epoch 900/1000: 0.057953424751758575\n",
      "Train Error: 0.056026287376880646\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 963/1000\n",
      "0.4: Correctly predicted: 973/1000\n",
      "0.5: Correctly predicted: 971/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 967/1000\n",
      "\n",
      "\n",
      "Learning Rate: 1\n",
      "lambda: 0.01\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6807270646095276\n",
      "Epoch 100/1000: 0.08321577310562134\n",
      "Epoch 200/1000: 0.07124444097280502\n",
      "Epoch 300/1000: 0.0642482340335846\n",
      "Epoch 400/1000: 0.059258636087179184\n",
      "Epoch 500/1000: 0.05538381263613701\n",
      "Epoch 600/1000: 0.05221769958734512\n",
      "Epoch 700/1000: 0.0495419055223465\n",
      "Epoch 800/1000: 0.04722600802779198\n",
      "Epoch 900/1000: 0.045186154544353485\n",
      "Train Error: 0.04338257759809494\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 966/1000\n",
      "0.4: Correctly predicted: 973/1000\n",
      "0.5: Correctly predicted: 973/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 966/1000\n",
      "\n",
      "lambda: 0.1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.7280785441398621\n",
      "Epoch 100/1000: 0.08360680937767029\n",
      "Epoch 200/1000: 0.07152116298675537\n",
      "Epoch 300/1000: 0.06441327929496765\n",
      "Epoch 400/1000: 0.059361279010772705\n",
      "Epoch 500/1000: 0.05544939264655113\n",
      "Epoch 600/1000: 0.05225977301597595\n",
      "Epoch 700/1000: 0.04956818372011185\n",
      "Epoch 800/1000: 0.04724114388227463\n",
      "Epoch 900/1000: 0.045193079859018326\n",
      "Train Error: 0.043383270502090454\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 967/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 974/1000\n",
      "0.6: Correctly predicted: 975/1000\n",
      "0.75: Correctly predicted: 965/1000\n",
      "\n",
      "lambda: 0.5\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6910464763641357\n",
      "Epoch 100/1000: 0.08302599936723709\n",
      "Epoch 200/1000: 0.07110463827848434\n",
      "Epoch 300/1000: 0.06414254009723663\n",
      "Epoch 400/1000: 0.059170227497816086\n",
      "Epoch 500/1000: 0.05530345067381859\n",
      "Epoch 600/1000: 0.05214093625545502\n",
      "Epoch 700/1000: 0.04946666210889816\n",
      "Epoch 800/1000: 0.04715132713317871\n",
      "Epoch 900/1000: 0.045111674815416336\n",
      "Train Error: 0.04330820590257645\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 966/1000\n",
      "0.4: Correctly predicted: 971/1000\n",
      "0.5: Correctly predicted: 974/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 965/1000\n",
      "\n",
      "lambda: 0.9\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.7148889303207397\n",
      "Epoch 100/1000: 0.0827789455652237\n",
      "Epoch 200/1000: 0.07033319771289825\n",
      "Epoch 300/1000: 0.0635308250784874\n",
      "Epoch 400/1000: 0.058724530041217804\n",
      "Epoch 500/1000: 0.05498078092932701\n",
      "Epoch 600/1000: 0.05190524458885193\n",
      "Epoch 700/1000: 0.04929281398653984\n",
      "Epoch 800/1000: 0.04702237993478775\n",
      "Epoch 900/1000: 0.04501597583293915\n",
      "Train Error: 0.04323742911219597\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 966/1000\n",
      "0.4: Correctly predicted: 972/1000\n",
      "0.5: Correctly predicted: 974/1000\n",
      "0.6: Correctly predicted: 974/1000\n",
      "0.75: Correctly predicted: 965/1000\n",
      "\n",
      "lambda: 1\n",
      "Training Error:\n",
      "Epoch 0/1000: 0.6782923340797424\n",
      "Epoch 100/1000: 552.2632446289062\n",
      "Epoch 200/1000: 1368.8450927734375\n",
      "Epoch 300/1000: 2233.83984375\n",
      "Epoch 400/1000: 3119.9658203125\n",
      "Epoch 500/1000: 4036.503662109375\n",
      "Epoch 600/1000: 4976.2939453125\n",
      "Epoch 700/1000: 5872.57470703125\n",
      "Epoch 800/1000: 6770.83447265625\n",
      "Epoch 900/1000: 7681.7509765625\n",
      "Train Error: 8635.8671875\n",
      "Thresholds:\n",
      "0.25: Correctly predicted: 887/1000\n",
      "0.4: Correctly predicted: 885/1000\n",
      "0.5: Correctly predicted: 884/1000\n",
      "0.6: Correctly predicted: 883/1000\n",
      "0.75: Correctly predicted: 882/1000\n",
      "\n",
      "\n",
      "Best Parameters: lr=1, lambda=0.1, threshold=0.6\n",
      "Best Performance: 975/1000\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent parameters\n",
    "learning_rates = [0.1, 0.5, 1]\n",
    "lambs = [0.01, 0.1, 0.5, 0.9, 1]\n",
    "thresholds = [0.25, 0.4, 0.5, 0.6, 0.75]\n",
    "num_iter = 1000\n",
    "\n",
    "max_correct = 0\n",
    "best_params = []\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "for learning_rate in learning_rates:\n",
    "    print(f\"Learning Rate: {learning_rate}\")\n",
    "    for lamb in lambs:\n",
    "        print(f\"lambda: {lamb}\")\n",
    "        model = LogisticRegressionGradientDescent(lr=learning_rate, lamb=lamb, num_iter=num_iter, x_dim=(X_train.shape[1] + 1))\n",
    "        model.fit(X_train, y_train_mod)\n",
    "        \n",
    "        print(\"Thresholds:\")\n",
    "        for threshold in thresholds:\n",
    "            preds = model.predict(X_test, threshold)\n",
    "            predictions = []\n",
    "            for pred in preds:\n",
    "                if pred:\n",
    "                    predictions.append(1)\n",
    "                else:\n",
    "                    predictions.append(0)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, val in enumerate(predictions):\n",
    "                total += 1\n",
    "                if val == y_test_mod[i]:\n",
    "                    correct += 1\n",
    "            if correct > max_correct:\n",
    "                max_correct = correct\n",
    "                best_params = [learning_rate, lamb, threshold]\n",
    "            print(f\"{threshold}: Correctly predicted: {correct}/{total}\")\n",
    "        print(\"\")\n",
    "    print(\"\")\n",
    "print(f\"Best Parameters: lr={best_params[0]}, lambda={best_params[1]}, threshold={best_params[2]}\")\n",
    "print(f\"Best Performance: {max_correct}/{total}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:49:52.191153800Z",
     "start_time": "2023-10-12T23:49:33.263090900Z"
    }
   },
   "id": "17890d4bfcf720e2"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "Epoch 0/1000: 0.6867411732673645\n",
      "Epoch 100/1000: 0.08304082602262497\n",
      "Epoch 200/1000: 0.07120714336633682\n",
      "Epoch 300/1000: 0.06420852243900299\n",
      "Epoch 400/1000: 0.059210795909166336\n",
      "Epoch 500/1000: 0.055330995470285416\n",
      "Epoch 600/1000: 0.052162718027830124\n",
      "Epoch 700/1000: 0.04948648810386658\n",
      "Epoch 800/1000: 0.04717110097408295\n",
      "Epoch 900/1000: 0.04513220489025116\n",
      "Train Error: 0.04332975298166275\n",
      "CPU times: total: 5.27 s\n",
      "Wall time: 1.33 s\n",
      "Accuracy: 974/1000\n"
     ]
    }
   ],
   "source": [
    "# Train the model again using the best parameters found in the grid sweep above\n",
    "model = LogisticRegressionGradientDescent(lr=best_params[0], lamb=best_params[1], num_iter=num_iter, x_dim=X_train.shape[1] + 1)\n",
    "%time model.fit(X_train, y_train_mod)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "preds = model.predict(X_test, best_params[2])\n",
    "predictions = []\n",
    "for pred in preds:\n",
    "    if pred:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, val in enumerate(predictions):\n",
    "    total += 1\n",
    "    if val == y_test_mod[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy: {correct}/{total}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T23:55:30.751153Z",
     "start_time": "2023-10-12T23:55:29.402571100Z"
    }
   },
   "id": "97c2d82ff5f1bbd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
